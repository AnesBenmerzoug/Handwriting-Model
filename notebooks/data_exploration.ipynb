{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5beda8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fe9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from handwriting_generator.constants import DATA_DIR\n",
    "from handwriting_generator.utils import (\n",
    "    load_line_strokes,\n",
    "    load_transcriptions,\n",
    "    plot_strokes,\n",
    "    filter_line_strokes_and_transcriptions,\n",
    "    convert_stroke_set_to_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703dcba",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "ascii_dir = DATA_DIR / \"ascii\"\n",
    "line_strokes_dir = DATA_DIR / \"lineStrokes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f9101",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_strokes = load_line_strokes(line_strokes_dir, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(line_strokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = load_transcriptions(ascii_dir, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1858973",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_strokes, transcriptions = filter_line_strokes_and_transcriptions(\n",
    "    line_strokes, transcriptions, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(line_strokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df27b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddabe2e",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.boxplot(sorted(list(map(len, transcriptions.values())), reverse=True))\n",
    "_ = plt.title(\"Distribution of transcription length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.boxplot(\n",
    "    sorted(list(map(lambda x: sum(map(len, x)), line_strokes.values())), reverse=True)\n",
    ")\n",
    "_ = plt.title(\"Distribution of line stroke length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99151a",
   "metadata": {},
   "source": [
    "Next, we will look at the distribution of characters in the different transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = Counter()\n",
    "\n",
    "for transcription in transcriptions.values():\n",
    "    all_characters.update(transcription)\n",
    "\n",
    "dict(sorted(all_characters.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c65939",
   "metadata": {},
   "source": [
    "As we can see clearly, the distribution of characters is imbalanced:\n",
    "\n",
    "- There are lowercase letters than uppercase letters => we will lowercase all the transcriptions\n",
    "- Some characters appear was less frequently than others => We will treat the least frequent ones as unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da023bfe",
   "metadata": {},
   "source": [
    "After that, we randomly select a stroke set and a transcription and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e459de",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(line_strokes), size=4)\n",
    "\n",
    "stroke_set_list = []\n",
    "transcription_list = []\n",
    "\n",
    "for idx in indices:\n",
    "    filename = tuple(line_strokes.keys())[idx]\n",
    "    stroke_set_list.append(line_strokes[filename])\n",
    "    transcription_list.append(transcriptions[filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2)\n",
    "for stroke_set, transcription, ax in zip(\n",
    "    stroke_set_list, transcription_list, axes.ravel()\n",
    "):\n",
    "    for strokes in stroke_set:\n",
    "        x, y = [], []\n",
    "        for i, point in enumerate(strokes):\n",
    "            x.append(int(point[0]))\n",
    "            y.append(int(point[1]))\n",
    "        ax.scatter(x, y, s=0.1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "    ax.set_title(transcription)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e90cef",
   "metadata": {},
   "source": [
    "As can be seen in some of the above examples, there is trend in the y-axis that should be\n",
    "removed because it will interefere with the model's training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0a919",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "for stroke_set, transcription, ax in zip(\n",
    "    stroke_set_list[:], transcription_list, axes.ravel()\n",
    "):\n",
    "    y = []\n",
    "\n",
    "    for strokes in stroke_set:\n",
    "        for point in strokes:\n",
    "            y.append(int(point[1]))\n",
    "\n",
    "    z = np.polyfit(np.arange(0, len(y)), y, deg=1)\n",
    "\n",
    "    counter = 0\n",
    "    for strokes in stroke_set:\n",
    "        x, y = [], []\n",
    "        for i, point in enumerate(strokes):\n",
    "            x.append(int(point[0]))\n",
    "            y.append(int(point[1]) - y_trend[counter])\n",
    "            counter += 1\n",
    "        ax.scatter(x, y, s=0.1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "    ax.set_title(transcription)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b5f95",
   "metadata": {},
   "source": [
    "Two other things we should do is to first reduce the scale of the x and y values as well as replace them with their respective 1st order differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6562e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "for stroke_set, transcription, ax in zip(\n",
    "    stroke_set_list, transcription_list, axes.ravel()\n",
    "):\n",
    "    arr = np.zeros((sum(map(len, stroke_set)), 3))\n",
    "\n",
    "    counter = -1\n",
    "    for strokes in stroke_set:\n",
    "        x, y = [], []\n",
    "        for i, point in enumerate(strokes):\n",
    "            counter += 1\n",
    "            arr[counter, 0] = int(point[0])\n",
    "            arr[counter, 1] = int(point[1])\n",
    "            arr[counter, 2] = point[0]\n",
    "        arr[counter, 2] = 1\n",
    "\n",
    "    # Remove trend on the y-axis\n",
    "    X = np.arange(0, len(arr))\n",
    "    z = np.polyfit(X, arr[:, 1], deg=1)\n",
    "    y_trend = np.polyval(z, X)\n",
    "    arr[:, 1] -= y_trend\n",
    "    # Normalize\n",
    "    arr[:, :2] = arr[:, :2] / np.max(arr[:, :2])\n",
    "    # Difference\n",
    "    arr[:, :2] = np.diff(arr[:, :2], prepend=0, axis=0)\n",
    "    # Plot\n",
    "    ax.scatter(np.cumsum(arr[:, 0]), np.cumsum(arr[:, 1]), s=0.1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "    ax.set_title(transcription)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99706c2a",
   "metadata": {},
   "source": [
    "Next, we put all of this pre-processing into a function to be able to reuse it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e31a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes_array_list = []\n",
    "for stroke_set in stroke_set_list:\n",
    "    strokes_array = convert_stroke_set_to_array(stroke_set)\n",
    "    strokes_array_list.append(strokes_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
